{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNnDmvgyvFK/2VDbvtUch9f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethvedbitdesjan/AI-ML_Training/blob/main/PyTorchIntro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxt0rCPLmN8i",
        "outputId": "84332a6d-02f3-470f-f951-e51ed756695c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor a: tensor([1., 2., 3., 4., 5.])\n"
          ]
        }
      ],
      "source": [
        "# Import PyTorch\n",
        "import torch\n",
        "\n",
        "# Create a tensor\n",
        "tensor_a = torch.Tensor([1, 2, 3, 4, 5])\n",
        "\n",
        "# Display the tensor\n",
        "print(\"Tensor a:\", tensor_a)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sliced_tensor = tensor_a[1:4]\n",
        "\n",
        "# Display the sliced tensor\n",
        "print(\"Sliced tensor:\", sliced_tensor)\n",
        "\n",
        "# Indexing a specific element\n",
        "element = tensor_a[2]\n",
        "\n",
        "# Display the element\n",
        "print(\"Element at index 2:\", element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frQu4tQem5YH",
        "outputId": "7a04b594-c25d-4784-bec9-1bb37e739ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sliced tensor: tensor([2., 3., 4.])\n",
            "Element at index 2: tensor(3.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "tensor_a = torch.Tensor([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "# Using view to reshape tensor\n",
        "reshaped_with_view = tensor_a.view(2, 3)\n",
        "\n",
        "# Using reshape to reshape tensor\n",
        "reshaped_with_reshape = tensor_a.reshape(2, 3)\n",
        "\n",
        "# Display the reshaped tensors\n",
        "print(\"\\nReshaped with view:\")\n",
        "print(reshaped_with_view)\n",
        "\n",
        "print(\"\\nReshaped with reshape:\")\n",
        "print(reshaped_with_reshape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPAi-ayUm7Ox",
        "outputId": "58ba0824-01cd-4ec2-b16f-53a7c9c58e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reshaped with view:\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "\n",
            "Reshaped with reshape:\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "view: Returns a new tensor with the same data but a different shape. The returned tensor shares the same data and must have the same number of elements. Throws an error if the sizes are incompatible.\n",
        "\n",
        "reshape: Returns a new tensor with the same data but a different shape. It may or may not share the data, depending on how the tensor is stored in memory."
      ],
      "metadata": {
        "id": "yEwmno3concI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenating two tensors\n",
        "tensor_b = torch.Tensor([6, 7, 8, 9, 10])\n",
        "concatenated_tensor = torch.cat((tensor_a, tensor_b), 0)\n",
        "\n",
        "# Display the concatenated tensor\n",
        "print(\"Concatenated tensor:\", concatenated_tensor)\n",
        "\n",
        "# Splitting the tensor into chunks\n",
        "split_tensors = torch.split(concatenated_tensor, 5)\n",
        "\n",
        "# Display the split tensors\n",
        "print(\"Split tensors:\", split_tensors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6pBEE4Mm9Rx",
        "outputId": "82b19bfc-f5d0-4a9e-9e87-673e910ca60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concatenated tensor: tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  6.,  7.,  8.,  9., 10.])\n",
            "Split tensors: (tensor([1., 2., 3., 4., 5.]), tensor([6., 6., 7., 8., 9.]), tensor([10.]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 2D tensor\n",
        "tensor_2d = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# Create a 3D tensor\n",
        "tensor_3d = torch.Tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]])\n",
        "\n",
        "# Create a 6D tensor\n",
        "tensor_6d = torch.Tensor(2, 2, 2, 2, 2, 2).fill_(1)  # Filling with ones for simplicity\n",
        "\n",
        "# Display the tensors\n",
        "print(\"2D Tensor:\")\n",
        "print(tensor_2d)\n",
        "\n",
        "# Slicing 2D tensor: Get the first 2 rows and first 2 columns\n",
        "sliced_2d = tensor_2d[:2, :2]\n",
        "print(\"\\nSliced 2D tensor (first 2 rows and first 2 columns):\")\n",
        "print(sliced_2d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiz3HMdem_0A",
        "outputId": "fe5ab020-6925-45c3-ee1a-874d4361cefb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D Tensor:\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.],\n",
            "        [7., 8., 9.]])\n",
            "\n",
            "Sliced 2D tensor (first 2 rows and first 2 columns):\n",
            "tensor([[1., 2.],\n",
            "        [4., 5.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n3D Tensor:\")\n",
        "print(tensor_3d)\n",
        "\n",
        "# Slicing 3D tensor: Get the first 2 \"blocks\", all rows, first column\n",
        "sliced_3d = tensor_3d[:2, :, :1]\n",
        "print(\"\\nSliced 3D tensor (first 2 blocks, all rows, first column):\")\n",
        "print(sliced_3d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmwgFGs_nnU-",
        "outputId": "1ae9886c-5748-49f2-dc0e-856925d9c62a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3D Tensor:\n",
            "tensor([[[ 1.,  2.],\n",
            "         [ 3.,  4.]],\n",
            "\n",
            "        [[ 5.,  6.],\n",
            "         [ 7.,  8.]],\n",
            "\n",
            "        [[ 9., 10.],\n",
            "         [11., 12.]]])\n",
            "\n",
            "Sliced 3D tensor (first 2 blocks, all rows, first column):\n",
            "tensor([[[1.],\n",
            "         [3.]],\n",
            "\n",
            "        [[5.],\n",
            "         [7.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercises"
      ],
      "metadata": {
        "id": "VvBFrroPmvCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# TODO: Create a 2D tensor of size 5x3 containing random integers between 1 and 10\n",
        "tensor_a = # Your code here\n",
        "\n",
        "# TODO: Create a 1D tensor of size 10 containing a sequence from 1 to 10\n",
        "tensor_b = # Your code here\n",
        "\n",
        "print(\"Tensor A:\")\n",
        "print(tensor_a)\n",
        "print(\"\\nTensor B:\")\n",
        "print(tensor_b)"
      ],
      "metadata": {
        "id": "8sVjmOONmxIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Given the following tensor\n",
        "tensor_c = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# TODO: Extract the second row from tensor_c\n",
        "second_row = # Your code here\n",
        "\n",
        "# TODO: Extract the first and third columns from tensor_c\n",
        "selected_columns = # Your code here\n",
        "\n",
        "print(\"Second Row:\")\n",
        "print(second_row)\n",
        "print(\"\\nSelected Columns:\")\n",
        "print(selected_columns)"
      ],
      "metadata": {
        "id": "uz9kKiLRmyzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Given the following tensor\n",
        "tensor_d = torch.arange(1, 13)\n",
        "\n",
        "# TODO: Reshape tensor_d into a 3x4 tensor\n",
        "reshaped_tensor = # Your code here\n",
        "\n",
        "print(\"Reshaped Tensor:\")\n",
        "print(reshaped_tensor)"
      ],
      "metadata": {
        "id": "SYRPcj4Vm01h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Given the following tensor\n",
        "tensor_h = torch.arange(1, 13)\n",
        "\n",
        "# TODO: Reshape tensor_h into a tensor with 4 rows and infer the number of columns using -1\n",
        "reshaped_tensor_h = # Your code here\n",
        "\n",
        "print(\"Reshaped Tensor H:\")\n",
        "print(reshaped_tensor_h)"
      ],
      "metadata": {
        "id": "84WiRnqqnEWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Given the following tensor\n",
        "tensor_i = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# TODO: Extract the last row from tensor_i using -1\n",
        "last_row = # Your code here\n",
        "\n",
        "print(\"Last Row:\")\n",
        "print(last_row)"
      ],
      "metadata": {
        "id": "SDcJlnCinLJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_e = torch.tensor([[1, 2], [3, 4]])\n",
        "tensor_f = torch.tensor([[5, 6], [7, 8]])\n",
        "\n",
        "# TODO: Perform element-wise addition of tensor_e and tensor_f\n",
        "sum_tensor = # Your code here\n",
        "\n",
        "# TODO: Calculate the mean of tensor_e\n",
        "mean_tensor_e = # Your code here\n",
        "\n",
        "# TODO: Perform matrix multiplication of tensor_e and tensor_f\n",
        "matmul_result = # Your code here\n",
        "\n",
        "print(\"Sum Tensor:\")\n",
        "print(sum_tensor)\n",
        "print(\"\\nMean of Tensor E:\")\n",
        "print(mean_tensor_e)\n",
        "print(\"\\nMatrix Multiplication Result:\")\n",
        "print(matmul_result)"
      ],
      "metadata": {
        "id": "cOTYJcbkm3LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Given the following tensor\n",
        "tensor_g = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# TODO: Calculate the sum of each row in tensor_g\n",
        "row_sum = # Your code here\n",
        "\n",
        "# TODO: Calculate the transpose of tensor_g\n",
        "transpose_g = # Your code here\n",
        "\n",
        "print(\"Row Sum:\")\n",
        "print(row_sum)\n",
        "print(\"\\nTranspose of Tensor G:\")\n",
        "print(transpose_g)"
      ],
      "metadata": {
        "id": "sa72Beccm5gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch Models"
      ],
      "metadata": {
        "id": "8ZQeiRvZnNBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define a simple linear layer with 2 input features and 1 output feature\n",
        "class SimpleLinearLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleLinearLayer, self).__init__()\n",
        "        self.linear = nn.Linear(2, 1)\n",
        "\n",
        "# Create an instance of the SimpleLinearLayer\n",
        "simple_layer = SimpleLinearLayer()\n",
        "\n",
        "# Display the layer\n",
        "print(\"Simple Linear Layer:\")\n",
        "print(simple_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qshMuIlpoI6S",
        "outputId": "da1cf4e1-32e5-4816-ceda-860d543355c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple Linear Layer:\n",
            "SimpleLinearLayer(\n",
            "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple feed-forward neural network\n",
        "class SimpleFeedForwardNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleFeedForwardNN, self).__init__()\n",
        "        self.layer1 = nn.Linear(2, 5)\n",
        "        self.layer2 = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the SimpleFeedForwardNN\n",
        "simple_nn = SimpleFeedForwardNN()\n",
        "\n",
        "# Create a sample input tensor\n",
        "input_tensor = torch.Tensor([[1.0, 2.0]])\n",
        "\n",
        "# Forward pass through the network\n",
        "output_tensor = simple_nn(input_tensor)\n",
        "\n",
        "# Display the output\n",
        "print(\"\\nOutput after forward pass:\")\n",
        "print(output_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zg6uynUot6h",
        "outputId": "3c5ffb8a-bb78-4f08-8db9-eafa9ef6919c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Output after forward pass:\n",
            "tensor([[-0.4920]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: Define a neural network with one hidden layer of size 10\n",
        "class ExerciseNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExerciseNN, self).__init__()\n",
        "        self.layer1 = nn.Linear(2, 10)\n",
        "        self.layer2 = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the ExerciseNN\n",
        "exercise_nn = ExerciseNN()\n",
        "\n",
        "# Create a sample input tensor\n",
        "exercise_input = torch.Tensor([[1.0, 2.0]])\n",
        "\n",
        "# Forward pass through the network\n",
        "exercise_output = exercise_nn(exercise_input)\n",
        "\n",
        "# Display the output\n",
        "print(\"\\nOutput of the exercise neural network:\")\n",
        "print(exercise_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT1m3ut-oxEg",
        "outputId": "f532be8e-cb4f-4743-f47b-7f9c62936a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Output of the exercise neural network:\n",
            "tensor([[-0.0623]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple feed-forward neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.layer1 = nn.Linear(2, 5)\n",
        "        self.layer2 = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the SimpleNN\n",
        "simple_nn = SimpleNN()\n",
        "\n",
        "# Create a sample input tensor\n",
        "input_tensor = torch.Tensor([[1.0, 2.0]])\n",
        "\n",
        "# Create a sample target tensor\n",
        "target_tensor = torch.Tensor([[0.0]])\n",
        "\n",
        "# Define a loss function and optimizer\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = optim.SGD(simple_nn.parameters(), lr=0.01)\n",
        "\n",
        "# Forward pass through the network\n",
        "output_tensor = simple_nn(input_tensor)\n",
        "\n",
        "# Compute the loss\n",
        "loss = loss_function(output_tensor, target_tensor)\n",
        "\n",
        "# Display the initial loss\n",
        "print(\"Initial Loss:\", loss.item())\n",
        "\n",
        "# Zero the gradients\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Backward pass (compute gradients)\n",
        "loss.backward()\n",
        "\n",
        "# Update the weights\n",
        "optimizer.step()\n",
        "\n",
        "# Forward pass through the network again\n",
        "output_tensor = simple_nn(input_tensor)\n",
        "\n",
        "# Compute the new loss\n",
        "new_loss = loss_function(output_tensor, target_tensor)\n",
        "\n",
        "# Display the new loss\n",
        "print(\"New Loss:\", new_loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxo_Q0r9qB8b",
        "outputId": "a328b235-5978-4dab-8b21-2b403eee955a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Loss: 0.17728237807750702\n",
            "New Loss: 0.15348653495311737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding a Simple Neural Network Example in PyTorch\n",
        "\n",
        "In this example, we define a simple neural network with one hidden layer. We then create a sample input and target tensor, and define a mean squared error loss function and a stochastic gradient descent optimizer.\n",
        "\n",
        "### Steps in the Example\n",
        "\n",
        "1. **Forward Pass**: We pass the input through the network to obtain the output.\n",
        "2. **Compute Loss**: The loss is computed by comparing the output and the target using a mean squared error loss function.\n",
        "3. **Zero Gradients**: Before performing the backward pass, we zero out the gradients to ensure they do not accumulate.\n",
        "4. **Backward Pass**: The `loss.backward()` function is called to compute the gradients for all parameters in the network.\n",
        "5. **Update Weights**: The optimizer updates the weights based on the computed gradients.\n",
        "\n",
        "### Understanding Backward and Autograd\n",
        "\n",
        "The `backward()` function computes the gradient of the loss with respect to each parameter using backpropagation. These gradients are stored in each parameter's `.grad` attribute and are used by the optimizer to update the weights.\n",
        "\n",
        "$$\n",
        "\\text{Gradient of Loss with respect to parameter} = \\frac{\\partial \\text{Loss}}{\\partial \\text{parameter}}$$\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "Feel free to run this code snippet to observe how the loss changes after a single update. This should provide a good understanding of how `backward()` and autograd work in PyTorch."
      ],
      "metadata": {
        "id": "9Khp_we3peUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('content/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB-s--pKpdgE",
        "outputId": "e8c7b584-afdf-45f8-e9bf-fd334197341d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/content/MyDrive/DLab_AI ML_Training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOGm-zqFo10N",
        "outputId": "3afbcdfc-0c33-4fe1-9884-0d49e5b1fa3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/content/MyDrive/DLab_AI ML_Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "BKLIPpcRuRdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Shakespeare text\n",
        "with open('input.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "text = text.lower()\n",
        "\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "M2EZocMjuXOB",
        "outputId": "71a06a38-5f9e-4a77-fac4-e7427f5ae1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'first citizen:\\nbefore we proceed any further, hear me speak.\\n\\nall:\\nspeak, speak.\\n\\nfirst citizen:\\nyou'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The data is not clean. It contains occurances of titles and subtitles which might interfere with the model's ability to learn the laguage.\n",
        "\n",
        "The next few cells clean the data\n",
        "'''\n",
        "prev = -1 #index of last group of '\\n'\n",
        "prev_word_idx = 1 #index of the last item that was not '\\n'\n",
        "prev_n = -1\n",
        "continuous= 0 #counting the consecutive '\\n'\n",
        "list_idx_to_remove = []\n",
        "for i in range(2, len(text)):\n",
        "  if text[i]=='\\n':\n",
        "    continuous+= 1\n",
        "  else:\n",
        "    prev_word_idx = i\n",
        "    continuous = 0\n",
        "  if continuous>1:\n",
        "    if (prev> -1) and (i - prev)==5:\n",
        "      if len(text[i-3])<40 and text[i-3]!='\\n':\n",
        "        list_idx_to_remove.append(i-3)\n",
        "        #remove next sentence if only the first is removed\n",
        "        if len(text[i-2])<40 and text[i-2]!='\\n':\n",
        "          list_idx_to_remove.append(i-2)\n",
        "    if(prev>-1) and (i-prev)==4:\n",
        "      if len(text[i-2])<40 and text[i-2]!='\\n':\n",
        "        list_idx_to_remove.append(i-2)\n",
        "    if continuous>2:\n",
        "      list_idx_to_remove.append(prev_word_idx)\n",
        "    prev = i-continuous + 1\n",
        "\n",
        "print(len(list_idx_to_remove), list_idx_to_remove[:5])\n",
        "\n",
        "list_idx_to_remove = list(set(list_idx_to_remove))\n",
        "list_idx_to_remove.sort()\n",
        "print(len(list_idx_to_remove))\n",
        "for idx_to_remove in list_idx_to_remove[11:13]:\n",
        "  print(text[idx_to_remove -3:idx_to_remove+3])\n",
        "  print(text[idx_to_remove])\n",
        "\n",
        "cleaned_text = []\n",
        "continuous = 0 #the number of consecutive '\\n'\n",
        "\n",
        "for i in range(len(text)):\n",
        "  line = text[i]\n",
        "  if line=='\\n':\n",
        "    continuous +=1\n",
        "  else:\n",
        "    continuous = 0\n",
        "\n",
        "  if i in list_idx_to_remove:\n",
        "    continue\n",
        "\n",
        "  if continuous>3:\n",
        "    continue\n",
        "  cleaned_text.append(line)\n",
        "\n",
        "print(len(cleaned_text), len(text))\n",
        "\n",
        "cleaned_text = \"\".join(cleaned_text)\n",
        "\n",
        "text = cleaned_text.lower()\n",
        "\n",
        "text[:200]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "So5NzA0jZWQL",
        "outputId": "f4abfb68-efc5-4681-a232-d94f08cddb8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 [442990, 919583]\n",
            "2\n",
            "1115392 1115394\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'first citizen:\\nbefore we proceed any further, hear me speak.\\n\\nall:\\nspeak, speak.\\n\\nfirst citizen:\\nyou are all resolved rather to die than to famish?\\n\\nall:\\nresolved. resolved.\\n\\nfirst citizen:\\nfirst, you'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Recurrent Neural Networks (RNNs) and LSTMs\n",
        "\n",
        "## Recurrent Neural Networks (RNNs)\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are a type of neural network architecture designed for sequence data. Unlike traditional feedforward neural networks, RNNs have connections that loop back within the network, allowing information to persist.\n",
        "\n",
        "![RNN Architecture](https://drive.google.com/uc?export=view&id=1Cr7Od8Tzm7FVDo5QG5wHn-iFzsANpAfx)\n",
        "\n",
        "### How RNNs Work\n",
        "\n",
        "1. **Sequence Data**: RNNs are ideal for sequence data like time series, speech, text, etc.\n",
        "2. **Hidden State**: The hidden state acts as the network's memory, capturing information from all past time steps.\n",
        "3. **Shared Parameters**: The same parameters are used for each input, making the network efficient and capable of handling sequences of varying lengths.\n",
        "\n",
        "---\n",
        "\n",
        "## Long Short-Term Memory (LSTM) Networks\n",
        "\n",
        "Long Short-Term Memory (LSTM) units are a special kind of RNN architecture capable of learning long-term dependencies. LSTMs are explicitly designed to avoid long-term dependency issues, making them more effective for sequence modeling tasks.\n",
        "\n",
        "![LSTM Architecture](https://drive.google.com/uc?export=view&id=1Z0IK859UF8atU1qmQKfoBIeOq6A_V8S8)\n",
        "\n",
        "### How LSTMs Work\n",
        "\n",
        "1. **Gates**: LSTMs have a complex cell structure with input, output, and forget gates that control the flow of information.\n",
        "2. **Cell State**: The cell state acts as a \"conveyor belt\" that carries relevant information across time steps, mitigating vanishing gradient problems.\n",
        "3. **Long-Term Dependencies**: LSTMs are capable of learning long-term dependencies thanks to their gating mechanisms.\n",
        "\n",
        "---\n",
        "\n",
        "## Understanding Gates in LSTM Units\n",
        "\n",
        "LSTMs have three main types of gates:\n",
        "\n",
        "1. **Input Gate**: Determines what information from the current input will be stored in the cell state.\n",
        "    \\[\n",
        "    i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi})\n",
        "    \\]\n",
        "   \n",
        "2. **Forget Gate**: Decides what information from the cell state should be thrown away or kept.\n",
        "    \\[\n",
        "    f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf})\n",
        "    \\]\n",
        "\n",
        "3. **Output Gate**: Determines what information from the cell state is sent as output.\n",
        "    \\[\n",
        "    o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho})\n",
        "    \\]\n",
        "\n",
        "### How Gates Work\n",
        "\n",
        "- **Input Gate**: Takes the current input \\( x_t \\) and the previous hidden state \\( h_{t-1} \\), and decides which values will be updated in the cell state.\n",
        "  \n",
        "- **Forget Gate**: Takes the current input \\( x_t \\) and the previous hidden state \\( h_{t-1} \\), and decides which values in the cell state should be discarded.\n",
        "\n",
        "- **Output Gate**: Takes the current input \\( x_t \\) and the modified cell state, and decides what should be the output \\( h_t \\).\n",
        "\n",
        "The gates use the sigmoid activation function \\( \\sigma \\) to squash values between 0 and 1, helping the LSTM unit to learn which information is important and which can be forgotten.\n"
      ],
      "metadata": {
        "id": "dRYWScXDrqKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "Lk-jztbU5nQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ShakespeareDataset(Dataset):\n",
        "    def __init__(self, text, sequence_length, chars, char_to_index, index_to_char):\n",
        "        self.text = text\n",
        "        self.sequence_length = sequence_length\n",
        "        self.chars = chars\n",
        "        self.char_to_index = char_to_index\n",
        "        self.index_to_char =index_to_char\n",
        "        self.text_indices = [self.char_to_index[char] for char in text]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text) - self.sequence_length - 1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.text_indices[index:index+self.sequence_length]\n",
        "        target = self.text_indices[index+self.sequence_length]\n",
        "        return torch.tensor(sequence), torch.tensor(target)\n"
      ],
      "metadata": {
        "id": "3b66tUUKHCig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# Hyperparameters\n",
        "sequence_length = 300\n",
        "BATCH_SIZE = 128\n",
        "hidden_size = 256\n",
        "num_layers = 2\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 3\n",
        "\n",
        "text = text[:300000]\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_index = {char: index for index, char in enumerate(chars)}\n",
        "index_to_char = {index: char for index, char in enumerate(chars)}\n",
        "\n",
        "shakespeare_dataset = ShakespeareDataset(text, sequence_length=sequence_length, chars=chars, char_to_index=char_to_index, index_to_char=index_to_char)\n",
        "\n",
        "train_size = int(0.8 * len(shakespeare_dataset))\n",
        "val_size = len(shakespeare_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(shakespeare_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n"
      ],
      "metadata": {
        "id": "Q7C_cw58Gu4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
        "        super(CharRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, h0):\n",
        "        x, hidden = self.lstm(x, h0)\n",
        "        # take only the last output\n",
        "        x = self.dropout(x)\n",
        "        x = x[:, -1, :]\n",
        "        x = x.contiguous().view(-1, hidden_size)\n",
        "        #print(x.shape)\n",
        "        # produce output\n",
        "        out = self.fc(x)\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(self.num_layers, batch_size, self.hidden_size).zero_(),\n",
        "                  weight.new(self.num_layers, batch_size, self.hidden_size).zero_())\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "V6xT0955Hnnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = CharRNN(1, hidden_size, num_layers, len(chars), 0.2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Mc_mEvsoHj2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC-LyAIVI1NW",
        "outputId": "20b142ec-8c8a-40f7-8829-428dd1bdb376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (lstm): LSTM(1, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=256, out_features=37, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "best_loss = 1e6\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    h = model.init_hidden(BATCH_SIZE)\n",
        "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
        "        X_batch = X_batch.to(torch.int64)\n",
        "        y_batch = y_batch.to(torch.int64)\n",
        "\n",
        "        #X_batch_onehot = torch.nn.functional.one_hot(X_batch, num_classes=len(chars)).float()\n",
        "        X_batch = X_batch.unsqueeze(2).float()\n",
        "        h = tuple([each.data.cuda() for each in h])\n",
        "        X_batch = X_batch.cuda()\n",
        "        try:\n",
        "            outputs, h = model(X_batch, h)\n",
        "        except Exception as e:\n",
        "            print(X_batch.shape, h[0].shape, h[1].shape, e)\n",
        "            raise(e)\n",
        "        #y_batch = torch.nn.functional.one_hot(y_batch, num_classes=len(chars)).float()\n",
        "        #print(y_batch.size(), outputs.size())\n",
        "        y_batch = y_batch.cuda()\n",
        "        loss = criterion(outputs, y_batch.long())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        h = model.init_hidden(BATCH_SIZE)\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch = X_batch.to(torch.int64)\n",
        "            y_batch = y_batch.to(torch.int64)\n",
        "\n",
        "            X_batch = X_batch.unsqueeze(2).float()\n",
        "            X_batch = X_batch.cuda()\n",
        "            h = tuple([each.data.cuda() for each in h])\n",
        "            #y_batch = torch.nn.functional.one_hot(y_batch, num_classes=len(chars)).float()\n",
        "            y_batch = y_batch.cuda()\n",
        "            outputs, h = model(X_batch, h)\n",
        "            loss = criterion(outputs, y_batch.long())\n",
        "            val_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Val Loss: {val_loss/len(val_loader)}\")\n",
        "    if val_loss < best_loss:\n",
        "        torch.save(model.state_dict(), 'model.pth')\n",
        "        print('saving...')\n",
        "        best_loss = val_loss\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwUbV93m1GYu",
        "outputId": "3a912809-7bb9-40f2-8afd-c8ba8e86b839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Batch [1/1873], Loss: 3.6273\n",
            "Epoch [1/3], Batch [101/1873], Loss: 3.0985\n",
            "Epoch [1/3], Batch [201/1873], Loss: 2.9323\n",
            "Epoch [1/3], Batch [301/1873], Loss: 3.0144\n",
            "Epoch [1/3], Batch [401/1873], Loss: 3.0144\n",
            "Epoch [1/3], Batch [501/1873], Loss: 2.7701\n",
            "Epoch [1/3], Batch [601/1873], Loss: 2.8728\n",
            "Epoch [1/3], Batch [701/1873], Loss: 2.9577\n",
            "Epoch [1/3], Batch [801/1873], Loss: 2.9850\n",
            "Epoch [1/3], Batch [901/1873], Loss: 2.7157\n",
            "Epoch [1/3], Batch [1001/1873], Loss: 2.9154\n",
            "Epoch [1/3], Batch [1101/1873], Loss: 2.8940\n",
            "Epoch [1/3], Batch [1201/1873], Loss: 2.7707\n",
            "Epoch [1/3], Batch [1301/1873], Loss: 2.8575\n",
            "Epoch [1/3], Batch [1401/1873], Loss: 2.8706\n",
            "Epoch [1/3], Batch [1501/1873], Loss: 2.8446\n",
            "Epoch [1/3], Batch [1601/1873], Loss: 2.7499\n",
            "Epoch [1/3], Batch [1701/1873], Loss: 2.7365\n",
            "Epoch [1/3], Batch [1801/1873], Loss: 2.8724\n",
            "Epoch 1/3, Val Loss: 2.733549403838622\n",
            "saving...\n",
            "Epoch [2/3], Batch [1/1873], Loss: 2.7530\n",
            "Epoch [2/3], Batch [101/1873], Loss: 2.5567\n",
            "Epoch [2/3], Batch [201/1873], Loss: 2.7015\n",
            "Epoch [2/3], Batch [301/1873], Loss: 2.5667\n",
            "Epoch [2/3], Batch [401/1873], Loss: 2.6493\n",
            "Epoch [2/3], Batch [501/1873], Loss: 2.7284\n",
            "Epoch [2/3], Batch [601/1873], Loss: 2.7219\n",
            "Epoch [2/3], Batch [701/1873], Loss: 2.5839\n",
            "Epoch [2/3], Batch [801/1873], Loss: 2.8844\n",
            "Epoch [2/3], Batch [901/1873], Loss: 2.6202\n",
            "Epoch [2/3], Batch [1001/1873], Loss: 2.5996\n",
            "Epoch [2/3], Batch [1101/1873], Loss: 2.5335\n",
            "Epoch [2/3], Batch [1201/1873], Loss: 2.5999\n",
            "Epoch [2/3], Batch [1301/1873], Loss: 2.8334\n",
            "Epoch [2/3], Batch [1401/1873], Loss: 2.7017\n",
            "Epoch [2/3], Batch [1501/1873], Loss: 2.7269\n",
            "Epoch [2/3], Batch [1601/1873], Loss: 2.8630\n",
            "Epoch [2/3], Batch [1701/1873], Loss: 2.6611\n",
            "Epoch [2/3], Batch [1801/1873], Loss: 2.5838\n",
            "Epoch 2/3, Val Loss: 2.629136403401693\n",
            "saving...\n",
            "Epoch [3/3], Batch [1/1873], Loss: 2.6715\n",
            "Epoch [3/3], Batch [101/1873], Loss: 2.7518\n",
            "Epoch [3/3], Batch [201/1873], Loss: 2.7360\n",
            "Epoch [3/3], Batch [301/1873], Loss: 2.6799\n",
            "Epoch [3/3], Batch [401/1873], Loss: 2.8338\n",
            "Epoch [3/3], Batch [501/1873], Loss: 2.8237\n",
            "Epoch [3/3], Batch [601/1873], Loss: 2.6329\n",
            "Epoch [3/3], Batch [701/1873], Loss: 2.6545\n",
            "Epoch [3/3], Batch [801/1873], Loss: 2.6444\n",
            "Epoch [3/3], Batch [901/1873], Loss: 2.6385\n",
            "Epoch [3/3], Batch [1001/1873], Loss: 2.6513\n",
            "Epoch [3/3], Batch [1101/1873], Loss: 2.6539\n",
            "Epoch [3/3], Batch [1201/1873], Loss: 2.6485\n",
            "Epoch [3/3], Batch [1301/1873], Loss: 2.4928\n",
            "Epoch [3/3], Batch [1401/1873], Loss: 2.6849\n",
            "Epoch [3/3], Batch [1501/1873], Loss: 2.4949\n",
            "Epoch [3/3], Batch [1601/1873], Loss: 2.6190\n",
            "Epoch [3/3], Batch [1701/1873], Loss: 2.4619\n",
            "Epoch [3/3], Batch [1801/1873], Loss: 2.7473\n",
            "Epoch 3/3, Val Loss: 2.5637808941368365\n",
            "saving...\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_text(model, initial_sequence, sequence_length, generate_length=100):\n",
        "    # Initialize hidden state\n",
        "    h0 = model.init_hidden(1)  # Batch size is 1 for inference\n",
        "    initial_sequence = initial_sequence.lower()\n",
        "    # Prepare initial sequence tensor\n",
        "    text_indices = [char_to_index[char] for char in initial_sequence]\n",
        "    initial_sequence = torch.tensor(text_indices)\n",
        "    #initial_sequence = initial_sequence.unsqueeze(0)\n",
        "    # Initialize generated text with the initial sequence\n",
        "    generated_text = initial_sequence.unsqueeze(0)[0].tolist()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(generate_length):\n",
        "            # Forward pass\n",
        "            initial = initial_sequence.unsqueeze(0).unsqueeze(2).float()\n",
        "            #initial_sequence_onehot = torch.nn.functional.one_hot(initial, num_classes=len(chars)).float().cuda()\n",
        "            h0 = tuple([each.data.cuda() for each in h0])\n",
        "            #print(initial_sequence_onehot.shape)\n",
        "            initial = initial.cuda()\n",
        "            output, h0 = model(initial, h0)\n",
        "\n",
        "            # Get the predicted character index\n",
        "            #print(output.shape)\n",
        "            output = output[-1, :]\n",
        "            #print(output.shape, output)\n",
        "            predicted = torch.topk(output, 3).indices\n",
        "            predicted = predicted.cpu().detach()\n",
        "            idx = random.randint(0, 2)\n",
        "            predicted = predicted[idx]\n",
        "            #print(predicted, predicted.item())\n",
        "            # Add the predicted character to the generated text\n",
        "            generated_text.append(predicted.item())\n",
        "            #print(predicted.unsqueeze(0).shape)\n",
        "            # Update the initial sequence to include the predicted character\n",
        "            initial_sequence = torch.cat((initial_sequence[1:], predicted.unsqueeze(0)), dim=0)\n",
        "            #print(initial_sequence.shape)\n",
        "\n",
        "    # Convert the generated text from indices to characters\n",
        "    generated_text = [shakespeare_dataset.index_to_char[index] for index in generated_text]\n",
        "\n",
        "    return ''.join(generated_text)\n",
        "\n",
        "# Load the trained model (replace 'model.pth' with your model's filename)\n",
        "model_path = 'model.pth'\n",
        "model = CharRNN(1, hidden_size, num_layers, len(chars), 0.2)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "model.cuda()\n",
        "\n",
        "# Provide an initial sequence to start generating text\n",
        "initial_sequence = \"\"\"f, that's off;\\ni would you rather had been silent. please you\\nto hear cominius speak?\\n\\nbrutus:\\nmost willingly;\\nbut yet my caution was more pertinent\\nthan the rebuke you give it.\\n\\nmenenius:\\nhe loves your people\\nbut tie him not to be their bedfellow.\\nworthy cominius, speak.\\nnay, keep your place.\\n\\nfirs \"\"\"\n",
        "\n",
        "# Generate text\n",
        "generated_text = generate_text(model, initial_sequence, sequence_length, generate_length=100)\n",
        "print(\"Generated Text:\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSpcbs38JJzs",
        "outputId": "765f1b24-a5f5-4bb0-8668-aa30522c6e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "f, that's off;\n",
            "i would you rather had been silent. please you\n",
            "to hear cominius speak?\n",
            "\n",
            "brutus:\n",
            "most willingly;\n",
            "but yet my caution was more pertinent\n",
            "than the rebuke you give it.\n",
            "\n",
            "menenius:\n",
            "he loves your people\n",
            "but tie him not to be their bedfellow.\n",
            "worthy cominius, speak.\n",
            "nay, keep your place.\n",
            "\n",
            "firs cndiierssser:::-tee,\n",
            "wo three,\n",
            "tour soerers,dn ioreress a wioe tiree the mo hoe aar aaneeeess,\n",
            "a mav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "04kluqM7ZSO0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}